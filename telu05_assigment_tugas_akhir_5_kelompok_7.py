# -*- coding: utf-8 -*-
"""TelU05_Assigment Tugas Akhir 5_Kelompok 7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PCXFXESkQhABui_dDS4hBnmDLMKqwuQj
"""

# import library dasar
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# import library for preprocessing
from sklearn.preprocessing import LabelEncoder

# Import Library for modelling
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import LinearSVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import roc_auc_score

# import metrics for evaluation
from sklearn.metrics import confusion_matrix
from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import classification_report

# me non aktifkan peringatan pada python dengan import warning -> 'ignore'
import warnings
warnings.filterwarnings('ignore')

"""# Load Dataset"""

# import dan tampilkan dataset
data = pd.read_csv('healthcare-dataset-stroke-data.csv')
data = pd.DataFrame(data)
data.head()

"""<h1> About Dataset </h1>
<h2> Context </h2>
According to the World Health Organization (WHO) stroke is the 2nd leading cause of death globally, responsible for approximately 11% of total deaths.
This dataset is used to predict whether a patient is likely to get stroke based on the input parameters like gender, age, various diseases, and smoking status. Each row in the data provides relavant information about the patient.

<h2> Attribute Information </h2>
1) id: unique identifier <br>
2) gender: "Male", "Female" or "Other" <br>
3) age: age of the patient <br>
4) hypertension: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension <br>
5) heart_disease: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease <br>
6) ever_married: "No" or "Yes" <br>
7) work_type: "children", "Govt_jov", "Never_worked", "Private" or "Self-employed" <br>
8) Residence_type: "Rural" or "Urban" <br>
9) avg_glucose_level: average glucose level in blood <br>
10) bmi: body mass index <br>
11) smoking_status: "formerly smoked", "never smoked", "smokes" or "Unknown"* <br>
12) stroke: 1 if the patient had a stroke or 0 if not <br>
*Note: "Unknown" in smoking_status means that the information is unavailable for this patient

# Data Preprocessing

Hal yang akan dilakukan:<br>
1. Menghilangkan kolom "Id".<br>
2. Menangani *missing value*.<br>
3. Menangani kategori *unknown*<br>
4. Melakukan transformasi data kategorik menjadi data numerik.<br>
5. Mencari korelasi antar field untuk seleksi fitur yang akan digunakan.<br>
6. Menangani *outlier*.
"""

# Menghilangkan kolom id karena sudah jelas tidak memengaruhi data manapun (hanya identifier)
data = data.drop(columns = 'id')
data.head()

# cek ukuran dataset
data.shape

# cek detail dari dataset
data.info()

# cek kemungkinan kejanggalan pada data
data.describe(include='all')

"""Nampak dari dataframe di atas bahwa field <b>bmi</b> memiliki *missing value*."""

# cari tahu jumlah missing values pada dataset
data.isna().sum()

# drop missing values dan atur indexnya
data = data.dropna()
data = data.reset_index(drop=True)

# hilangkan data "Other" dari gender dan "Unknown" dari smoking_status karena tidak memiliki makna untuk dimodelkan
data = data.drop((data[data['gender']=="Other"]).index, axis=0)               #Gender other akan mengganggu model
data = data.drop((data[data['smoking_status']=="Unknown"]).index, axis=0)     #Smoking_status unknown akan mengganggu model
data = data.reset_index(drop=True)
data.shape

# ubah data kategorik menjadi data numerik
le = LabelEncoder()
data['gender'] = le.fit_transform(data['gender'])
data['ever_married'] = le.fit_transform(data['ever_married'])
data['work_type'] = le.fit_transform(data['work_type'])
data['Residence_type'] = le.fit_transform(data['Residence_type'])
data['smoking_status'] = le.fit_transform(data['smoking_status'])
print("Data kategorik telah diencode menjadi data numerik")
print("""- gender: "Male" = 1, "Female" = 0, or "Other" = 2
- ever_married: "No" = 0 or "Yes" = 1
- work_type: "children" = 4, "Govt_jov" = 0, "Never_worked" = 1, "Private" = 2 or "Self-employed" = 3
- Residence_type: "Rural" = 0 or "Urban" = 1
- smoking_status: "formerly smoked" = 1, "never smoked" = 2, "smokes" = 3 or "Unknown" = 0
""")

# mendapatkan korelasi di setiap fitur dalam dataset
corrmat = data.corr()
top_corr_features = corrmat.index
plt.figure(figsize=(10,5))

# plot heatmap
h = sns.heatmap(data[top_corr_features].corr(),annot=True,cmap="RdYlGn")

"""Nampak bahwa 4 variabel bebas yang paling berkorelasi dengan status stroke pasien berturut-turut adalah <b>age</b>, <b>hypertension</b>, <b>heart_disease</b>, dan <b>avg_glucose_level</b>. Field lain bisa dihapus."""

data = data.drop(columns = 'gender')
data = data.drop(columns = 'ever_married')
data = data.drop(columns = 'work_type')
data = data.drop(columns = 'Residence_type')
data = data.drop(columns = 'bmi')
data = data.drop(columns = 'smoking_status')
data

sns.boxplot(data['age'])

# cek outlier pada avg_glucose_level
sns.boxplot(data['avg_glucose_level'])

# fungsi untuk mendeteksi nilai outlier
def detect_outliers(data, x):
    Q1 = data[x].describe()['25%']
    Q3 = data[x].describe()['75%']
    IQR = Q3-Q1
    data = data.drop(((data[x] < Q1-1.5*IQR) | (data[x] > Q3+1.5*IQR)).index, axis=0)
    data = data.reset_index(drop=True)
    return data[(data[x] < Q1-1.5*IQR) | (data[x] > Q3+1.5*IQR)]

# outlier avg_glucose_level
detect_outliers(data,'avg_glucose_level')

# outlier avg_glucose_level
detect_outliers(data,'age')

# cek ukuran dataset final setelah dibersihkan
data.shape

"""SAMPAI TAHAP INI, DATA TELAH BERSIH DAN SIAP DIGUNAKAN UNTUK MEMBANGUN MODEL.

# Data Modelling

Hal yang akan dilakukan:<br>
1. Menentukan variabel bebas dan variabel target.<br>
2. Split data.<br>
3. Bangun model.<br>
4. Evaluasi.
"""

# tentukan kolom variabel bebas (X) dan kolom target (y) --> ingin melihat faktor yang memengaruhi stroke
X = data.iloc[:,0:4]
y = data.iloc[:,-1]

# split data
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=0)

"""<h2> K Nearest Neighbors </h2>"""

model_knn = KNeighborsClassifier()
param_grid = {'n_neighbors' : np.arange(3,51), 'weights' : ['uniform','distance']}
gscv = GridSearchCV(model_knn, param_grid, scoring=make_scorer(roc_auc_score), cv = 10)
gscv.fit(X_train, y_train)
gscv.best_params_

model_knn = KNeighborsClassifier(n_neighbors = gscv.best_params_['n_neighbors'], weights = gscv.best_params_['weights'])
model_knn.fit(X_train, y_train)  
Y_pred = model_knn.predict(X_test) 
accuracy_knn=round(accuracy_score(y_test,Y_pred)* 100, 2)
acc_k_n_n = round(decision_tree.score(X_train, y_train) * 100, 2)

cm = confusion_matrix(y_test, Y_pred)
accuracy = accuracy_score(y_test,Y_pred)
precision = precision_score(y_test, Y_pred,average='micro')
recall = recall_score(y_test, Y_pred,average='micro')
f1 = f1_score(y_test,Y_pred,average='micro')
sns.heatmap(cm, annot = True)
print('accuracy_KNN: %.3f' %accuracy)
print('precision_KNN: %.3f' %precision)
print('recall_KNN: %.3f' %recall)
print('f1-score_KNN : %.3f' %f1)

import pickle

Pkl_Filename = "model_tree.pkl"  

with open(Pkl_Filename, 'wb') as file:  
    pickle.dump(decision_tree, file)

import pydantic

from pydantic import BaseModel

class Stroke(BaseModel):
  age: int
  hypertension: bool
  heart_disease: bool
  avg_glucose_level: float
  class Config:
    schema_extra = {
        "example": {
            "age": 45,
            "hypertension": 1,
            "heart_disease": 1,
            "avg_glucose_level": 274.95
            }
        }

from fastapi import FastAPI
import pickle

app = FastAPI()

@app.on_event("startup")
def load_model():
    global model
    model = pickle.load(open("model_tree.pkl", "rb"))

@app.get('/')
def index():
    return {'message': 'This is the homepage of the API '}


@app.post('/predict')
def get_stroke_status(data: Stroke):
    received = data.dict()
    age = received['age']
    hypertension = received['hypertension']
    heart_disease = received['heart_disease']
    avg_glucose_level = received['avg_glucose_level']
    pred_name = model.predict([[age, hypertension, heart_disease, avg_glucose_level]]).tolist()[0]
    return {'prediction': pred_name}

from colabcode import ColabCode
server = ColabCode(port=10000, code=False)
server.run_app(app=app)